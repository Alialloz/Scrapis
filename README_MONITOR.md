# üìä Syst√®me de Monitoring Centris

Ce syst√®me d√©tecte automatiquement les nouvelles annonces sur Centris, les scrape et envoie les donn√©es √† votre API.

## üéØ Fonctionnalit√©s

- ‚úÖ **D√©tection automatique** des nouvelles annonces
- ‚úÖ **M√©moire persistante** des annonces d√©j√† scrap√©es
- ‚úÖ **Scraping complet** : toutes les donn√©es + photos
- ‚úÖ **Envoi automatique** √† votre API
- ‚úÖ **Monitoring continu** avec intervalle configurable
- ‚úÖ **Sauvegarde locale** de chaque annonce en JSON

## üìÅ Fichiers

- `scraper_monitor.py` : Script principal de monitoring
- `config_monitor.json` : Configuration (URL, API endpoint, etc.)
- `scraped_properties.json` : Liste des annonces d√©j√† scrap√©es (cr√©√© automatiquement)
- `property_XXXXXXXX.json` : Donn√©es individuelles de chaque propri√©t√© scrap√©e

## üöÄ Utilisation

### 1. Configuration de l'API

√âditez `scraper_monitor.py` ligne 286 :

```python
API_ENDPOINT = "https://votre-api.com/api/properties"
```

Ou configurez directement dans le code :

```python
monitor = CentrisMonitor(
    url=MATRIX_URL,
    api_endpoint="https://votre-api.com/api/properties",
    storage_file='scraped_properties.json'
)
```

### 2. Mode: Cycle Unique

Lance un seul cycle de monitoring (scan + scrape les nouvelles annonces) :

```bash
python scraper_monitor.py
```

### 3. Mode: Monitoring Continu

Pour un monitoring continu, modifiez la fonction `main()` dans `scraper_monitor.py` :

```python
def main():
    MATRIX_URL = "https://matrix.centris.ca/..."
    API_ENDPOINT = "https://votre-api.com/api/properties"
    
    monitor = CentrisMonitor(
        url=MATRIX_URL,
        api_endpoint=API_ENDPOINT
    )
    
    # Monitoring continu toutes les 60 minutes
    monitor.run_continuous_monitoring(interval_minutes=60)
```

Puis lancez :

```bash
python scraper_monitor.py
```

Pour arr√™ter : `Ctrl+C`

## üìä Flux de Donn√©es

```
1. Scan de la page Matrix
   ‚Üì
2. Extraction de tous les num√©ros Centris
   ‚Üì
3. Comparaison avec scraped_properties.json
   ‚Üì
4. Si nouvelles annonces d√©tect√©es:
   - Scraping complet (donn√©es + 9 photos)
   - Sauvegarde dans property_XXXXXXXX.json
   - Envoi √† l'API (POST JSON)
   - Ajout √† scraped_properties.json
```

## üì¶ Format JSON envoy√© √† l'API

```json
{
  "prix": "750000",
  "adresse": "220Z-226BZ Boul. Pierre-Bertrand",
  "ville": "Qu√©bec",
  "arrondissement": "Les Rivi√®res",
  "quartier": "Neufch√¢tel-Est/Lebourgneuf",
  "type_propriete": "Autre",
  "annee_construction": "1949",
  "numero_centris": "23326443",
  "date_envoi": "2025-12-15",
  "statut": "Nouvelle annonce",
  "donnees_financieres": { ... },
  "unites": { ... },
  "caracteristiques_detaillees": { ... },
  "inclusions": "...",
  "exclusions": "...",
  "remarques": "...",
  "addenda": "...",
  "photo_urls": [
    "https://mspublic.centris.ca/media.ashx?id=...",
    ...
  ],
  "nb_photos": 9,
  "courtier_email": "mguimont@rayharvey.ca",
  "courtier_telephone": "418-849-7777"
}
```

## üîß API Requirements

Votre API doit accepter :
- **M√©thode**: POST
- **Content-Type**: application/json
- **Body**: JSON complet de la propri√©t√©
- **R√©ponse attendue**: Status 200 ou 201 pour succ√®s

Exemple d'endpoint (Node.js/Express) :

```javascript
app.post('/api/properties', (req, res) => {
  const propertyData = req.body;
  
  // Sauvegarder dans votre base de donn√©es
  db.properties.insert(propertyData);
  
  res.status(201).json({ 
    success: true, 
    message: 'Propri√©t√© enregistr√©e',
    numero_centris: propertyData.numero_centris 
  });
});
```

## üìà Monitoring et Logs

Le script affiche :
- Nombre total d'annonces sur la page
- Nombre de nouvelles annonces d√©tect√©es
- Statut du scraping pour chaque annonce
- Statut de l'envoi √† l'API
- R√©sum√© du cycle

Exemple de sortie :

```
=== CYCLE DE MONITORING - 2025-12-18 15:30:00 ===
[OK] 24 annonces trouv√©es sur la page
[NOUVEAU] 3 nouvelle(s) annonce(s) d√©tect√©e(s):
  - No Centris: 23326443
  - No Centris: 23326444
  - No Centris: 23326445

SCRAPING DE L'ANNONCE No Centris: 23326443
[OK] Donn√©es sauvegard√©es dans property_23326443.json
[API] Envoi des donn√©es √† https://votre-api.com/api/properties...
[OK] Donn√©es envoy√©es avec succ√®s (Status: 201)

R√âSUM√â DU CYCLE
Total annonces sur la page: 24
Nouvelles annonces: 3
Scrap√©es avec succ√®s: 3
Envoy√©es √† l'API: 3
Erreurs: 0
```

## ‚öôÔ∏è Personnalisation

### Changer l'intervalle de monitoring

```python
monitor.run_continuous_monitoring(interval_minutes=30)  # Toutes les 30 min
```

### Ajouter des headers personnalis√©s √† l'API

Modifiez la m√©thode `send_to_api()` :

```python
headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer VOTRE_TOKEN',
    'X-Custom-Header': 'valeur'
}
```

### Filtrer certains types de propri√©t√©s

Dans `identify_new_listings()`, ajoutez des conditions :

```python
# Scraper seulement les propri√©t√©s > 500 000$
if property_data['prix'] > 500000:
    self.send_to_api(property_data)
```

## üêõ D√©pannage

### Probl√®me: L'API ne re√ßoit pas les donn√©es

1. V√©rifiez que `API_ENDPOINT` est correctement configur√©
2. V√©rifiez les logs pour voir la r√©ponse de l'API
3. Testez votre endpoint avec curl :
   ```bash
   curl -X POST https://votre-api.com/api/properties \
     -H "Content-Type: application/json" \
     -d @property_23326443.json
   ```

### Probl√®me: Certaines annonces ne sont pas d√©tect√©es

1. V√©rifiez que la page a bien charg√© (augmentez les `time.sleep`)
2. V√©rifiez le fichier `scraped_properties.json` pour voir quels IDs sont d√©j√† enregistr√©s
3. Supprimez `scraped_properties.json` pour tout rescraper

### Probl√®me: Le scraping est trop lent

1. Le scraping complet (avec photos) prend ~60 secondes par annonce
2. D√©sactivez le scraping des photos pour acc√©l√©rer (√† impl√©menter si besoin)

## üìù Notes Importantes

- ‚ö†Ô∏è **Respect du serveur** : Un d√©lai de 5 secondes est impos√© entre chaque scraping
- üíæ **Stockage** : Chaque annonce g√©n√®re un fichier JSON (~5-10 KB)
- üîÑ **Idempotence** : Une annonce scrap√©e ne sera jamais re-scrap√©e (sauf si vous supprimez `scraped_properties.json`)
- üì∑ **Photos** : Les 9 URLs de photos sont incluses dans le JSON (liens directs vers les images)

## üöÄ D√©ploiement en Production

Pour un monitoring 24/7, utilisez :

### Option 1: Cron (Linux)

```bash
# √âditer crontab
crontab -e

# Ajouter (ex√©cuter toutes les heures)
0 * * * * cd /path/to/Scrapis && python scraper_monitor.py
```

### Option 2: Service Windows

Cr√©ez une t√¢che planifi√©e Windows qui ex√©cute `scraper_monitor.py` toutes les heures.

### Option 3: Docker

```dockerfile
FROM python:3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "scraper_monitor.py"]
```

## üìû Support

Pour toute question ou probl√®me, consultez les logs du script ou contactez le d√©veloppeur.

