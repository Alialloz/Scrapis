# Syst√®me de Logging

Documentation du syst√®me de logging du scraper Centris.

## üìÅ Structure des logs

```
logs/
‚îú‚îÄ‚îÄ scraper.log         # Log principal avec rotation (10 MB max)
‚îú‚îÄ‚îÄ scraper.log.1       # Backup 1
‚îú‚îÄ‚îÄ scraper.log.2       # Backup 2
‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ scraper.log.7       # Backup 7 (7 jours d'historique)
‚îî‚îÄ‚îÄ errors.log          # Erreurs uniquement
```

## üîß Configuration

Le syst√®me de logging est configur√© dans `logger_config.py` :

- **Rotation automatique** : 10 MB par fichier
- **R√©tention** : 7 fichiers de backup (environ 1 semaine)
- **Format** : `YYYY-MM-DD HH:MM:SS | LEVEL | LOGGER | MESSAGE`
- **Encodage** : UTF-8

## üìä Niveaux de log

- **DEBUG** : Informations d√©taill√©es (d√©veloppement)
- **INFO** : Informations g√©n√©rales (production)
- **WARNING** : Avertissements
- **ERROR** : Erreurs r√©cup√©rables
- **CRITICAL** : Erreurs critiques

## üíª Utilisation dans le code

### Configuration basique

```python
from logger_config import setup_logger

# Logger principal
logger = setup_logger('scraper', level='INFO')

logger.info("D√©marrage du scraping...")
logger.warning("Attention : pas d'inclusions trouv√©es")
logger.error("Erreur lors de l'extraction")
```

### Logger d'erreurs

```python
from logger_config import setup_error_logger

error_logger = setup_error_logger()
error_logger.error("Erreur critique captur√©e")
```

### Logs structur√©s

```python
from logger_config import log_scraping_stats, log_extraction_result

# Statistiques
stats = {
    'Nouvelles annonces': 5,
    'Annonces scrap√©es': 5,
    'Dur√©e': '3m 45s'
}
log_scraping_stats(logger, stats)

# R√©sultat d'extraction
property_data = {...}
log_extraction_result(logger, property_data, success=True)
```

## üîç Analyse des logs

### Script d'analyse automatique

```bash
# Analyser les derni√®res 24 heures
python analyze_logs.py

# Analyser les derni√®res 48 heures
python analyze_logs.py 48
```

Le script affiche :
- ‚úÖ Taux de r√©ussite des extractions
- üìä Messages par niveau (INFO, WARNING, ERROR)
- üì∏ Statistiques photos
- ‚ùå Derni√®res erreurs
- ‚è∞ Activit√© par heure
- ‚ö†Ô∏è  Probl√®mes d√©tect√©s

### Commandes utiles (Serveur)

```bash
# Voir les logs en temps r√©el
tail -f logs/scraper.log

# Voir les 100 derni√®res lignes
tail -100 logs/scraper.log

# Voir uniquement les erreurs
grep "ERROR" logs/scraper.log

# Chercher un pattern sp√©cifique
grep "Centris #24886125" logs/scraper.log

# Compter les extractions r√©ussies aujourd'hui
grep "$(date +%Y-%m-%d)" logs/scraper.log | grep "Extraction r√©ussie" | wc -l

# Voir les erreurs du jour
grep "$(date +%Y-%m-%d)" logs/errors.log
```

## üìà Surveillance Production

### Sur le serveur DigitalOcean

Les logs sont √©galement captur√©s par systemd :

```bash
# Logs systemd (sortie standard)
journalctl -u scraper-centris -f

# Logs systemd (derni√®res 100 lignes)
journalctl -u scraper-centris -n 100

# Logs systemd + fichiers
tail -f /var/log/scraper-centris.log
tail -f logs/scraper.log
```

### Rotation automatique

Le syst√®me utilise `RotatingFileHandler` de Python :
- Cr√©e automatiquement les backups `.1`, `.2`, etc.
- Supprime automatiquement les anciens fichiers
- Pas besoin de logrotate

## üö® D√©tection de probl√®mes

Le script `analyze_logs.py` d√©tecte automatiquement :

- ‚ö†Ô∏è  Taux d'√©chec > 10%
- ‚ö†Ô∏è  Plus de 10 erreurs
- ‚ö†Ô∏è  Pas d'activit√© depuis > 2h
- ‚ö†Ô∏è  Moyenne de photos < 10

## üõ†Ô∏è D√©veloppement vs Production

### D√©veloppement (local)
```python
logger = setup_logger('scraper', level='DEBUG', log_to_console=True)
```
- Niveau DEBUG pour tout voir
- Affichage console + fichier

### Production (serveur)
```python
logger = setup_logger('scraper', level='INFO', log_to_console=True)
```
- Niveau INFO pour √©viter trop de verbosit√©
- Console captur√©e par systemd
- Fichiers avec rotation

## üìù Exemples de logs

```
2026-01-25 08:30:45 | INFO     | scraper | D√©marrage du monitoring...
2026-01-25 08:30:46 | INFO     | scraper | Chargement de la page Matrix
2026-01-25 08:30:50 | INFO     | scraper | ‚úì Extraction r√©ussie - Centris #24886125
2026-01-25 08:30:50 | DEBUG    | scraper |   Adresse: 390 Rue des Lilas E.
2026-01-25 08:30:50 | DEBUG    | scraper |   Prix: 699000 $
2026-01-25 08:30:50 | DEBUG    | scraper |   Photos: 48
2026-01-25 08:30:50 | DEBUG    | scraper |   Source: RE/MAX 1ER CHOIX INC., Agence immobili√®re
2026-01-25 08:31:15 | WARNING  | scraper | Pas d'inclusions trouv√©es
2026-01-25 08:31:45 | ERROR    | scraper | Impossible de cliquer sur la propri√©t√©
```

## üîÑ Migration depuis print()

Remplacer progressivement :
```python
# Ancien
print("[OK] Chrome initialise")
print(f"[ERREUR] {e}")

# Nouveau
logger.info("Chrome initialise")
logger.error(f"Erreur: {e}", exc_info=True)
```

L'argument `exc_info=True` ajoute automatiquement le traceback complet.
